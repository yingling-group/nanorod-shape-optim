{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2721461-404a-4096-9ac6-05f25484f3b9",
   "metadata": {},
   "source": [
    "```bash\n",
    "## TO RUN THIS NOTEBOOK FROM THE TERMINAL\n",
    "$ jupyter nbconvert --to script x10_classifier_pipeline.ipynb\n",
    "$ python x10_classifier_pipeline.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2910f7fa-d920-47b3-87be-1bf52b107c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import kernels, GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed6695-ff69-44f0-a3b1-7f2da32b7ba0",
   "metadata": {},
   "source": [
    "### Common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d3191bb-1005-47e7-bf47-9f82f0f35f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline as pl\n",
    "from model import plotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f57f69-274c-4b49-b66b-2640fcea0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.AdData import *\n",
    "from model.AdFeatures import *\n",
    "from model.AdClassify import TestPerformance\n",
    "from model import hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb17055-207a-4d89-90ae-ac94913f222b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pipeline' from '/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e4ed7-7fc5-44fe-897c-0d93af35be5f",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437a0743-bdf6-4c66-aa57-18506e38db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlib.load_fonts(\"../../../common/fonts/\")\n",
    "plt.style.use(\"matplotlib.mplstyle\")\n",
    "\n",
    "inputCsv = \"../Data/imputed_data.mice.csv\"\n",
    "ignoreXCols = ['imp', 'id', 'quality', 'lobe', 'full', 'other', 'coatingId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c53e34-361f-450c-b9cc-e8ed0fbfb472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- LoadData() ... \n",
      "\t Add coating classes: ['full', 'other', 'lobe']\n",
      "\t Test IDs: [9, 21, 30, 16, 23, 28]\n",
      "\t Test classes: ['other', 'lobe', 'lobe', 'full', 'full', 'full']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "xCols: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = LoadData()\n",
    "loader.Execute(inputCsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bcfd0-ad87-4b0e-89bf-6133ae9a0f47",
   "metadata": {},
   "source": [
    "### Define grid pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5b3864-28a1-47d3-91f9-7c7ffaecd18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [\n",
    "    loader,\n",
    "    (\n",
    "        ObservedData(),\n",
    "        ImputedData()\n",
    "    ),\n",
    "    pl.SetYCol('coatingId'),\n",
    "    pl.Set(scoring='f1_weighted'),\n",
    "    pl.DropCol('coating'),\n",
    "    (\n",
    "        pl.AllValidFeatures(ignoreCols=ignoreXCols),\n",
    "        pl.NonCollinearFeatures(keepCols=['teosVolPct', 'teosVolume'],\n",
    "                             ignoreCols=ignoreXCols, show=False),\n",
    "    ),\n",
    "    pl.AugmentByQuality(F=2, scale=0.3, qcol='quality'),\n",
    "    (\n",
    "        None,\n",
    "        pl.AugmentImb(RandomOverSampler()),\n",
    "        pl.AugmentImb(BorderlineSMOTE()),\n",
    "        pl.AugmentImb(SMOTE()),\n",
    "        pl.AugmentImb(ADASYN()),\n",
    "    ),\n",
    "    AggregateFeatures(show=False),\n",
    "    pl.ScaleX(allColumns=False),\n",
    "    (\n",
    "        # SetModel(RandomForestClassifier()),\n",
    "        pl.SetModel(DecisionTreeClassifier()),\n",
    "    ),\n",
    "    (\n",
    "        None,\n",
    "        pl.SelectFeaturesRFE(show=True)\n",
    "    ),\n",
    "    (\n",
    "        # SetModel(XGBClassifier()),\n",
    "        pl.SetModel(KNeighborsClassifier()),\n",
    "        # SetModel(SVC()),\n",
    "        # SetModel(GaussianProcessClassifier()),\n",
    "        # SetModel(RandomForestClassifier()),\n",
    "    ),\n",
    "    pl.SearchHyperParams(hyperparams.space),\n",
    "    TestPerformance(show=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a71183-dafe-4dff-8598-5d5604222463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 01:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.8967097403005723\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 01.\n",
      "\n",
      "Pipeline 02:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 3-fold CV with DecisionTreeClassifier() selected 6 features.\n",
      "\t ['tsfw2', 'tsfw3', 'lspk3', 'lsfw3', 'teosVolume', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.8967097403005723\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 02.\n",
      "\n",
      "Pipeline 03:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: RandomOverSampler ... \n",
      "\t Old shape: (143, 21), New shape: (330, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.9346180480932255\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 03.\n",
      "\n",
      "Pipeline 04:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: RandomOverSampler ... \n",
      "\t Old shape: (143, 21), New shape: (330, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 3-fold CV with DecisionTreeClassifier() selected 8 features.\n",
      "\t ['tsfw1', 'tsfw2', 'tspk3', 'tsfw3', 'lspk3', 'lsfw3', 'teosVolume', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.9456146192988298\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.40      0.67      0.50         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.13      0.22      0.17         6\n",
      "\t weighted avg       0.20      0.33      0.25         6\n",
      "\n",
      "Done 04.\n",
      "\n",
      "Pipeline 05:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: BorderlineSMOTE ... \n",
      "\t Old shape: (143, 21), New shape: (143, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.8967097403005723\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 05.\n",
      "\n",
      "Pipeline 06:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: BorderlineSMOTE ... \n",
      "\t Old shape: (143, 21), New shape: (233, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 3-fold CV with DecisionTreeClassifier() selected 10 features.\n",
      "\t ['tspk2', 'tsfw2', 'lspk2', 'lsfw2', 'tspk3', 'tsfw3', 'lspk3', 'lsfw3', 'teosVolume', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.9130728292018615\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 06.\n",
      "\n",
      "Pipeline 07:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: SMOTE ... \n",
      "\t Old shape: (143, 21), New shape: (330, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1).\n",
      "\t Best score: 0.9346180480932255\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.40      0.67      0.50         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.13      0.22      0.17         6\n",
      "\t weighted avg       0.20      0.33      0.25         6\n",
      "\n",
      "Done 07.\n",
      "\n",
      "Pipeline 08:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: SMOTE ... \n",
      "\t Old shape: (143, 21), New shape: (330, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 3-fold CV with DecisionTreeClassifier() selected 7 features.\n",
      "\t ['tsfw2', 'tspk3', 'tsfw3', 'lspk3', 'lsfw3', 'teosVolume', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.9456146192988298\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.25      0.33      0.29         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.17         6\n",
      "\t    macro avg       0.08      0.11      0.10         6\n",
      "\t weighted avg       0.12      0.17      0.14         6\n",
      "\n",
      "Done 08.\n",
      "\n",
      "Pipeline 09:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: ADASYN ... L09 FAILED: Not any neigbours belong to the majority class. This case will induce a NaN case with a division by zero. ADASYN is not suited for this specific dataset. Use SMOTE instead.\n",
      "Done 09.\n",
      "\n",
      "Pipeline 10:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py\", line 119, in _pipeline\n",
      "    X = adapter.Execute(X, i+1, self.muted)\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py\", line 78, in Execute\n",
      "    X = self.Process(X)\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/AdAugment.py\", line 23, in Process\n",
      "    Xs, ys = self.overSampler.fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/over_sampling/_adasyn.py\", line 183, in _fit_resample\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Not any neigbours belong to the majority class. This case will induce a NaN case with a division by zero. ADASYN is not suited for this specific dataset. Use SMOTE instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: ADASYN ... L10 FAILED: Not any neigbours belong to the majority class. This case will induce a NaN case with a division by zero. ADASYN is not suited for this specific dataset. Use SMOTE instead.\n",
      "Done 10.\n",
      "\n",
      "Pipeline 11:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py\", line 119, in _pipeline\n",
      "    X = adapter.Execute(X, i+1, self.muted)\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py\", line 78, in Execute\n",
      "    X = self.Process(X)\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/AdAugment.py\", line 23, in Process\n",
      "    Xs, ys = self.overSampler.fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/over_sampling/_adasyn.py\", line 183, in _fit_resample\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Not any neigbours belong to the majority class. This case will induce a NaN case with a division by zero. ADASYN is not suited for this specific dataset. Use SMOTE instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.8967097403005723\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 11.\n",
      "\n",
      "Pipeline 12:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 3-fold CV with DecisionTreeClassifier() selected 6 features.\n",
      "\t ['tsfw2', 'tsfw1', 'teosVolume', 'lspk1', 'tspk1', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1).\n",
      "\t Best score: 1.0\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 12.\n",
      "\n",
      "Pipeline 13:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: RandomOverSampler ... \n",
      "\t Old shape: (143, 21), New shape: (330, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.9456146192988298\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 13.\n",
      "\n",
      "Pipeline 14:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: RandomOverSampler ... \n",
      "\t Old shape: (143, 21), New shape: (330, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 3-fold CV with DecisionTreeClassifier() selected 5 features.\n",
      "\t ['tsfw2', 'tsfw1', 'lspk1', 'tspk1', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1).\n",
      "\t Best score: 1.0\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 14.\n",
      "\n",
      "Pipeline 15:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: BorderlineSMOTE ... \n",
      "\t Old shape: (143, 21), New shape: (233, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.9233026682419395\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 15.\n",
      "\n",
      "Pipeline 16:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: BorderlineSMOTE ... \n",
      "\t Old shape: (143, 21), New shape: (143, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 3-fold CV with DecisionTreeClassifier() selected 5 features.\n",
      "\t ['tsfw2', 'teosVolume', 'lspk1', 'tspk1', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1).\n",
      "\t Best score: 1.0\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 16.\n",
      "\n",
      "Pipeline 17:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: SMOTE ... \n",
      "\t Old shape: (143, 21), New shape: (330, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1, p=1).\n",
      "\t Best score: 0.9456146192988298\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 17.\n",
      "\n",
      "Pipeline 18:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: SMOTE ... \n",
      "\t Old shape: (143, 21), New shape: (330, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 3-fold CV with DecisionTreeClassifier() selected 5 features.\n",
      "\t ['tsfw2', 'teosVolume', 'lspk1', 'tspk1', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 3-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=1).\n",
      "\t Best score: 1.0\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 18.\n",
      "\n",
      "Pipeline 19:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: ADASYN ... L19 FAILED: Not any neigbours belong to the majority class. This case will induce a NaN case with a division by zero. ADASYN is not suited for this specific dataset. Use SMOTE instead.\n",
      "Done 19.\n",
      "\n",
      "Pipeline 20:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ObservedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- NonCollinearFeatures() ... \n",
      "\t Selected 9 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py\", line 119, in _pipeline\n",
      "    X = adapter.Execute(X, i+1, self.muted)\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py\", line 78, in Execute\n",
      "    X = self.Process(X)\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/AdAugment.py\", line 23, in Process\n",
      "    Xs, ys = self.overSampler.fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/over_sampling/_adasyn.py\", line 183, in _fit_resample\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Not any neigbours belong to the majority class. This case will induce a NaN case with a division by zero. ADASYN is not suited for this specific dataset. Use SMOTE instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Old shape: (16, 21), New shape: (143, 21)\n",
      "\n",
      " -- AugmentImb: ADASYN ... L20 FAILED: Not any neigbours belong to the majority class. This case will induce a NaN case with a division by zero. ADASYN is not suited for this specific dataset. Use SMOTE instead.\n",
      "Done 20.\n",
      "\n",
      "Pipeline 21:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ImputedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py\", line 119, in _pipeline\n",
      "    X = adapter.Execute(X, i+1, self.muted)\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py\", line 78, in Execute\n",
      "    X = self.Process(X)\n",
      "  File \"/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/AdAugment.py\", line 23, in Process\n",
      "    Xs, ys = self.overSampler.fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/site-packages/imblearn/over_sampling/_adasyn.py\", line 183, in _fit_resample\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Not any neigbours belong to the majority class. This case will induce a NaN case with a division by zero. ADASYN is not suited for this specific dataset. Use SMOTE instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t Old shape: (120, 21), New shape: (845, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... \n",
      "\t 5-fold CV HyperParam search for KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=9, p=1).\n",
      "\t Best score: 0.979593607933689\n",
      "\n",
      " -- TestPerformance() ... \n",
      "                        result\n",
      "100% accuracy            False\n",
      "5/6 accuracy             False\n",
      "100% accuracy on lobe    False\n",
      "80% accuracy on lobe     False\n",
      "100% accuracy on full    False\n",
      "80% accuracy on full     False\n",
      "100% accuracy on other   False\n",
      "80% accuracy on other    False\n",
      "\n",
      "\t SCORE: 0\n",
      "\t               precision    recall  f1-score   support\n",
      "\t \n",
      "\t            0       0.50      0.67      0.57         3\n",
      "\t            1       0.00      0.00      0.00         1\n",
      "\t            2       0.00      0.00      0.00         2\n",
      "\t \n",
      "\t     accuracy                           0.33         6\n",
      "\t    macro avg       0.17      0.22      0.19         6\n",
      "\t weighted avg       0.25      0.33      0.29         6\n",
      "\n",
      "Done 21.\n",
      "\n",
      "Pipeline 22:\n",
      "=============================== >>\n",
      " -- LoadData() ... ok\n",
      " -- ImputedData() ... ok\n",
      " -- SetYCol() ... 'coatingId' ok\n",
      " -- Set: scoring ... \n",
      "\t {'scoring': 'f1_weighted'}\n",
      "\n",
      " -- DropCol() ... ok\n",
      " -- AllValidFeatures() ... \n",
      "\t Selected 14 features.\n",
      "\n",
      " -- AugmentByQuality: F=2 scale=0.30 ... \n",
      "\t Old shape: (120, 21), New shape: (845, 21)\n",
      "\n",
      " -- AggregateFeatures() ... ok\n",
      " -- ScaleX: StandardScaler ... \n",
      "\t Scaled xCols, non xCols are unchanged.\n",
      "\n",
      " -- SetModel: DecisionTreeClassifier ... ok\n",
      " -- SelectFeaturesRFE() ... \n",
      "\t RFE 5-fold CV with DecisionTreeClassifier() selected 5 features.\n",
      "\t ['lsfw1', 'tsfw2', 'tspk3', 'lsfw3', 'teosVolPct']\n",
      "\n",
      " -- SetModel: KNeighborsClassifier ... ok\n",
      " -- SearchHyperParams() ... running grid search ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7fb59ad03e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akhlak/miniconda3/lib/python3.9/_weakrefset.py\", line 45, in _remove\n",
      "    self.data.discard(item)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m reload(pl)\n\u001b[1;32m      2\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mGridLine(grid)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputCsv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py:152\u001b[0m, in \u001b[0;36mGridLine.Execute\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid)):\n\u001b[0;32m--> 152\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExecuteLine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mappend(X)\n",
      "File \u001b[0;32m/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py:144\u001b[0m, in \u001b[0;36mGridLine.ExecuteLine\u001b[0;34m(self, lineNo, X)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     xclone \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m--> 144\u001b[0m newX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxclone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone \u001b[39m\u001b[38;5;132;01m%02d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newX\n",
      "File \u001b[0;32m/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py:119\u001b[0m, in \u001b[0;36mGridLine._pipeline\u001b[0;34m(self, i, pipe, X)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;132;01m%02d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)]\u001b[38;5;241m.\u001b[39mappend(utils\u001b[38;5;241m.\u001b[39mnice_name(adapter))\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmuted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    121\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exception(\u001b[38;5;28mtype\u001b[39m(err), err, err\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/pipeline.py:78\u001b[0m, in \u001b[0;36mAdapter.Execute\u001b[0;34m(self, X, i, mute)\u001b[0m\n\u001b[1;32m     74\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_newline(i)\n\u001b[0;32m---> 78\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rep:\n",
      "File \u001b[0;32m/home/hdd/Dropbox/work-Proj/Proj-UV-GNR-ML/code/pipeline/AdHyperParam.py:38\u001b[0m, in \u001b[0;36mSearchHyperParams.Process\u001b[0;34m(self, pl)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m     37\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m pl\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msayf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-fold CV HyperParam search for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m           pl\u001b[38;5;241m.\u001b[39mcv, pl\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(pl)\n",
    "pipe = pipeline.GridLine(grid)\n",
    "pipe.Execute(inputCsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dbdd922-9398-47e9-b063-eb6f436ca604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    score model xcols       S01           S02      S03           S04      S05  \\\n",
      "L01     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L02     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L23     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L24     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L25     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L26     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L27     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L28     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L29     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L30     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L31     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L32     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L33     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L34     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L35     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L36     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L37     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L38     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L39     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L22     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L21     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "L20     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L10     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L03     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L04     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L05     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L06     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L07     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L08     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L09     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L11     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L19     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L12     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L13     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L14     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L15     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L16     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L17     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L18     0  None        LoadData  ObservedData  SetYCol  Set: scoring  DropCol   \n",
      "L40     0  None        LoadData   ImputedData  SetYCol  Set: scoring  DropCol   \n",
      "\n",
      "                                  S06  \n",
      "L01  AugmentByQuality: F=2 scale=0.30  \n",
      "L02  AugmentByQuality: F=2 scale=0.30  \n",
      "L23  AugmentByQuality: F=2 scale=0.30  \n",
      "L24  AugmentByQuality: F=2 scale=0.30  \n",
      "L25  AugmentByQuality: F=2 scale=0.30  \n",
      "L26  AugmentByQuality: F=2 scale=0.30  \n",
      "L27  AugmentByQuality: F=2 scale=0.30  \n",
      "L28  AugmentByQuality: F=2 scale=0.30  \n",
      "L29  AugmentByQuality: F=2 scale=0.30  \n",
      "L30  AugmentByQuality: F=2 scale=0.30  \n",
      "L31  AugmentByQuality: F=2 scale=0.30  \n",
      "L32  AugmentByQuality: F=2 scale=0.30  \n",
      "L33  AugmentByQuality: F=2 scale=0.30  \n",
      "L34  AugmentByQuality: F=2 scale=0.30  \n",
      "L35  AugmentByQuality: F=2 scale=0.30  \n",
      "L36  AugmentByQuality: F=2 scale=0.30  \n",
      "L37  AugmentByQuality: F=2 scale=0.30  \n",
      "L38  AugmentByQuality: F=2 scale=0.30  \n",
      "L39  AugmentByQuality: F=2 scale=0.30  \n",
      "L22  AugmentByQuality: F=2 scale=0.30  \n",
      "L21  AugmentByQuality: F=2 scale=0.30  \n",
      "L20  AugmentByQuality: F=2 scale=0.30  \n",
      "L10  AugmentByQuality: F=2 scale=0.30  \n",
      "L03  AugmentByQuality: F=2 scale=0.30  \n",
      "L04  AugmentByQuality: F=2 scale=0.30  \n",
      "L05  AugmentByQuality: F=2 scale=0.30  \n",
      "L06  AugmentByQuality: F=2 scale=0.30  \n",
      "L07  AugmentByQuality: F=2 scale=0.30  \n",
      "L08  AugmentByQuality: F=2 scale=0.30  \n",
      "L09  AugmentByQuality: F=2 scale=0.30  \n",
      "L11  AugmentByQuality: F=2 scale=0.30  \n",
      "L19  AugmentByQuality: F=2 scale=0.30  \n",
      "L12  AugmentByQuality: F=2 scale=0.30  \n",
      "L13  AugmentByQuality: F=2 scale=0.30  \n",
      "L14  AugmentByQuality: F=2 scale=0.30  \n",
      "L15  AugmentByQuality: F=2 scale=0.30  \n",
      "L16  AugmentByQuality: F=2 scale=0.30  \n",
      "L17  AugmentByQuality: F=2 scale=0.30  \n",
      "L18  AugmentByQuality: F=2 scale=0.30  \n",
      "L40  AugmentByQuality: F=2 scale=0.30  \n"
     ]
    }
   ],
   "source": [
    "res = pipe.Summarize()\n",
    "print(res)\n",
    "try:\n",
    "    res.to_csv(\"gridline_results.csv\")\n",
    "except:\n",
    "    input(\"Please close the excel file if open and press enter ...\")\n",
    "    res.to_csv(\"gridline_results.csv\")\n",
    "    print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade8565-e962-4f7b-9fbb-29804bffdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_ipython:\n",
    "    def system(*args):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca430c7-52d1-44f4-9cd4-115d80fa979f",
   "metadata": {},
   "source": [
    "```bash\n",
    "## RUN THIS NOTEBOOK FROM THE TERMINAL\n",
    "$ jupyter nbconvert --to script PlayGround.ipynb\n",
    "$ python PlayGround.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
